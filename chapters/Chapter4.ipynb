{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chapter 3 - When old models of computing fail\n",
    "\n",
    "## Hadoop and Spark\n",
    "\n",
    "Paul E. Anderson\n",
    "\n",
    "Source: https://www.datadoghq.com/blog/hadoop-architecture-overview/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Ice Breaker\n",
    "\n",
    "Favorite place for ice cream in SLO (wait it's too cold for that)...\n",
    "\n",
    "Favorite place for pizza in SLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "While this text can be viewed as PDF, it is most useful to have a Jupyter environment. I have an environment ready for each of you, but you can get your own local environment going in several ways. One popular way is with Anaconda (<a href=\"https://www.anaconda.com/\">https://www.anaconda.com/</a>. Because of the limited time, you can use my server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Update on lab grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src='../labs/grade_summary.png' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What's wrong with our previous approaches?\n",
    "* Apache Hadoop is a framework for distributed computation and storage of very large data sets on computer clusters\n",
    "* Hadoop began as a project to implement Google’s MapReduce programming model\n",
    "* Hadoop has seen widespread adoption by many companies including Facebook, Yahoo!, Adobe, Cisco, eBay, Netflix, and Datadog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### That didn't answer the question\n",
    "Consider our needs?\n",
    "* We want a programming model that can process data many times the size that can be processed by a single computer\n",
    "* This level of coordination and abstraction can be difficult to achieve for a general purpose computing language such a Python. \n",
    "* Hadoop brings a paradigm shift in the following sense:\n",
    "    * Simplying our programming constructs (i.e., limit us to Map Reduce)\n",
    "    * Providing the architecture to support the computing we need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Hadoop Distributed File System\n",
    "* underlying file system of a Hadoop cluster\n",
    "* designed with hardware failure in mind\n",
    "* built for large datasets, with a default block size of 128 MB\n",
    "* optimized for sequential operations\n",
    "* rack-aware\n",
    "* cross-platform and supports heterogeneous clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Data in a Hadoop cluster is broken down into smaller units (called blocks) \n",
    "* Blocks are distributed throughout the cluster\n",
    "* Each block is duplicated twice (for a total of three copies) \n",
    "* Two replicas stored on two nodes in a rack somewhere else in the cluster\n",
    "* Highly available and fault-tolerant\n",
    "* HDFS will automatically re-replicate it elsewhere in the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://imgix.datadoghq.com/img/blog/hadoop-architecture-overview/hadoop-architecture-diagram3.png?auto=format&fit=max&w=847\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### NameNode\n",
    "* leader\n",
    "* brokers access to files by clients\n",
    "* operates entirely in memory\n",
    "* persisting its state to disk\n",
    "* One single point of failure for a Hadoop cluster\n",
    "\n",
    "Clients communicate directly with DataNodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MapReduce\n",
    "* Perfect for distributed computing of large data\n",
    "* three operations: \n",
    "    * map an input data set into a collection of <key,value> pairs\n",
    "    * shuffle the resulting data (transfer data to the reducers)\n",
    "    * then reduce over all pairs with the same key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://imgix.datadoghq.com/img/blog/hadoop-architecture-overview/hadoop-architecture-diagram1-3.png?auto=format&fit=max&w=847\" width=2000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### YARN (Yet Another Resource Negotiator)\n",
    "Consists of three components\n",
    "* ResourceManager (one per cluster)\n",
    "* ApplicationMaster (one per application)\n",
    "* NodeManagers (one per node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://imgix.datadoghq.com/img/blog/hadoop-architecture-overview/hadoop-architecture-diagram8.png?auto=format&fit=max&w=847\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ResourceManager\n",
    "* Rack-aware leader node in YARN. \n",
    "* Takes inventory of available resources\n",
    "* Runs Scheduler.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ApplicationMaster\n",
    "* Each application running on Hadoop has its own dedicated ApplicationMaster instance. \n",
    "* Each application’s ApplicationMaster periodically sends heartbeat messages to the ResourceManager, as well as requests for additional resources, if needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Yarn Flow\n",
    "1. Client program submits the MapReduce application to the ResourceManager, along with information to launch the application-specific ApplicationMaster.\n",
    "2. ResourceManager negotiates a container for the ApplicationMaster and launches the ApplicationMaster.\n",
    "3. ApplicationMaster boots and registers with the ResourceManager, allowing the original calling client to interface directly with the ApplicationMaster.\n",
    "4. ApplicationMaster negotiates resources (resource containers) for client application.\n",
    "5. ApplicationMaster gives the container launch specification to the NodeManager, which launches a container for the application.\n",
    "6. During execution, client polls ApplicationMaster for application status and progress.\n",
    "7. Upon completion, ApplicationMaster deregisters with the ResourceManager and shuts down, returning its containers to the resource pool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### So when did Hadoop come out?\n",
    "Well Google's MapReduce paper came out in 2004 - http://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf\n",
    "\n",
    "Hadoop and Spark work well together, and such a combination is very common. We will discuss Spark next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to Spark\n",
    "* Built around speed (in-memory enabled)\n",
    "* ETL (extract, transform, load)\n",
    "* Interactive queries (SQL)\n",
    "* Advanced analytics (e.g., machine learning)\n",
    "* Streaming over large datasets in a wide range of data stores (e.g., HDFS, Cassandra, HBase, S3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### RDDs\n",
    "* Resilient Distributed Dataset (RDD)\n",
    "* Fault tolerant like hadoop\n",
    "* Allows parallel operations upon itself\n",
    "* RDDs can be created from Hadoop InputFormats (such as HDFS files) OR\n",
    "* by transforming other RDDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Spark SQL\n",
    "* Designed for processing structured and semi-structured data\n",
    "* Provides a DataFrame API for data manipulations. \n",
    "* DataFrame is conceptually similar to a table in relational database.\n",
    "* Represents a distributed collection of data organized into named columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MLLib\n",
    "<a href=\"https://spark.apache.org/mllib/\">https://spark.apache.org/mllib/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Streaming\n",
    "<a href=\"https://spark.apache.org/docs/latest/streaming-programming-guide.html\">https://spark.apache.org/docs/latest/streaming-programming-guide.html</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### GraphX\n",
    "<a href=\"https://spark.apache.org/graphx/\">https://spark.apache.org/graphx/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What are the main responsibilities of the NameNode?\n",
    "\n",
    "\n",
    "#### Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. In general terms (i.e., don't get into Spark and language details), what is the output of the map stage?\n",
    "\n",
    "\n",
    "#### Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Has Spark replaced Hadoop? Should it replace Hadoop?\n",
    "\n",
    "\n",
    "#### Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Conclusion\n",
    "* Hadoop and Spark make up two pillars of the modern data engineering ecosystem. \n",
    "* We won't need to implement these (already done). We do need to understand them and use them.\n",
    "* We will work our way through these technologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_code_all_hidden": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,md,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
