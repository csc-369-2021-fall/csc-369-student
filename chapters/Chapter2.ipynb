{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chapter 2\n",
    "\n",
    "## Distributed computing at the command line\n",
    "\n",
    "Paul E. Anderson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Ice Breaker\n",
    "\n",
    "What's is the best pizza place in SLO?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "While this text can be viewed as PDF, it is most useful to have a Jupyter environment. I have an environment ready for each of you, but you can get your own local environment going in several ways. One popular way is with Anaconda (<a href=\"https://www.anaconda.com/\">https://www.anaconda.com/</a>. Because of the limited time, you can use my server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# Put all your solutions into Lab1_helper.py as this script which is autograded\n",
    "import Chapter2_helper \n",
    "\n",
    "from pathlib import Path\n",
    "home = str(Path.home()) # all other paths are relative to this path. \n",
    "# This is not relevant to most people because I recommended you use my server, but\n",
    "# change home to where you are storing everything. Again. Not recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line\n",
    "\n",
    "In Chapter 1, I included several videos where you had to follow along as I entered commands on the command line. In this chapter we are going to increase our mastery of the command line and distributed computing at the same time. \n",
    "\n",
    "The command line is very agile. It has a read-eval-print loop that lends itself to interactive exploration as well as automation. It has been a mainstay in the toolkit of modern computer science, and it will remain so for a long time to come.\n",
    "\n",
    "The command line augments and amplifies technology we are already using. We'll use Spark, Hadoop, MongoDB, and other programs in this class. The command line is important across these technologies. \n",
    "\n",
    "The command line is scalable which is very important for distributed computing. It allows us to automate many tasks and scale them in a distributed manner.\n",
    "\n",
    "The command line is ubiquitous. 95% of the worlds supercomputers use Unix/Linux and are accessible by the command line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How are distributed systems different?\n",
    "While we can abstract away some of elements of distributed computing, we are going to study approaches for:\n",
    "1. How to store data on multiple systems?\n",
    "2. How to handle updates and fix (or handle) inconsistencies?\n",
    "3. How do we assemble the full answer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Practical Considerations\n",
    "Most real world examples that need distributed computing need distributed computing because they would otherwise (and may still) require a long time to run. This isn't practical for learning. More importantly to remember, even in the real world we test on small subsets of data before scaling up. All of the examples throughout are scaled down representations of a real problem that may require distributed computing depending on time and resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel Processing Logs\n",
    "Consider the cybersecurity task of examining web server logs. Specifically, read/skim this article in groups of three:\n",
    "<a href=\"https://resources.infosecinstitute.com/topic/log-analysis-web-attacks-beginners-guide/\">Log Analysis</a>.\n",
    "\n",
    "Once you have read the article, consider the problem of running Scalp on a single log. Probably not an issue. Consider running it on a very large log (web server logs can get very very big). \n",
    "\n",
    "Because they can get big they are often archived routinely. So now you have a problem of looking through many different log files. We may want to run Scalp on the logs over a long period of time. We may want to run it with different parameters. We may make mistakes and need to run it again quickly. You are starting to get my point I think.\n",
    "\n",
    "Would this problem need distributed computing. Discuss in your groups and bring the answer back in a few minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**It boils down to these questions for us over and over again (some of these overlap):**\n",
    "* Do I need a more efficient (i.e., faster) approach?\n",
    "* Can my task be broken down into components that may be analyzed and then combined?\n",
    "* Is it worth the effort? \n",
    "* Can you just wait for this answer?\n",
    "* Can you estimate how long a non-distributed approach will take?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Stop and consider\n",
    "We will be jumping straight into command line usage examples. Dependening on your comfort level you may want to flip down to the **\"Detour: Linux and Bash\"** section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Project Gutenberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider another example. What if you were interested in looking for patterns in the top 100 books last year? Your first idea is to compare the word frequencies in the top 25 books to the next 25 books. \n",
    "* You have a level of programming skill that makes writing a Python program to look through a single book (text file) within range. \n",
    "* You are familiar with Python dictionaries and can sequentially process a book. \n",
    "\n",
    "Let's design such a program together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There is a list of books downloaded from Project Gutenberg in the data folder\n",
    "* Website has over 60,000 books. \n",
    "* I downloaded the most popular books on 1/12/2021 \n",
    "* The order in which they are ranked is in order.txt. \n",
    "\n",
    "Let's see a few Bash commands to take a look at the books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080-0.txt  158-0.txt\t 2542-0.txt   41-0.txt\t     6130-0.txt   84-0.txt\n",
      "11-0.txt    160-0.txt\t 2554-0.txt   42108-0.txt    6133-0.txt   863-0.txt\n",
      "113-0.txt   16-0.txt\t 2591-0.txt   4300-0.txt     64238-0.txt  902-0.txt\n",
      "1184-0.txt  1661-0.txt\t 25929-0.txt  43-0.txt\t     64239-0.txt  98-0.txt\n",
      "120-0.txt   1727-0.txt\t 2600-0.txt   45-0.txt\t     64241-0.txt  996-0.txt\n",
      "1232-0.txt  1952-0.txt\t 2701-0.txt   4517-0.txt     64242-0.txt  group1\n",
      "1250-0.txt  1998-0.txt\t 28054-0.txt  46-0.txt\t     64244-0.txt  group2\n",
      "1260-0.txt  203-0.txt\t 2814-0.txt   50040-0.txt    64246-0.txt  group3\n",
      "1342-0.txt  205-0.txt\t 2852-0.txt   50040-0.txt.1  64247-0.txt  order.txt\n",
      "135-0.txt   209-0.txt\t 30254-0.txt  521-0.txt      730-0.txt\n",
      "1399-0.txt  215-0.txt\t 35-0.txt     53854-0.txt    74-0.txt\n",
      "1400-0.txt  219-0.txt\t 3600-0.txt   57426-0.txt    76-0.txt\n",
      "140-0.txt   244-0.txt\t 36-0.txt     58585-0.txt    766-0.txt\n",
      "147-0.txt   25344-0.txt  408-0.txt    60479-0.txt    768-0.txt\n"
     ]
    }
   ],
   "source": [
    "!ls {home}/csc-369-student/data/gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "!ls -l {home}/csc-369-student/data/gutenberg | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50040\n",
      "1342\n",
      "84\n",
      "6133\n",
      "46\n",
      "11\n",
      "1080\n",
      "1661\n",
      "98\n",
      "25344\n"
     ]
    }
   ],
   "source": [
    "!head {home}/csc-369-student/data/gutenberg/order.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Python code to create a list of files in the ranked order**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/gutenberg/50040-0.txt',\n",
       " '../data/gutenberg/1342-0.txt',\n",
       " '../data/gutenberg/84-0.txt',\n",
       " '../data/gutenberg/6133-0.txt',\n",
       " '../data/gutenberg/46-0.txt',\n",
       " '../data/gutenberg/11-0.txt',\n",
       " '../data/gutenberg/1080-0.txt',\n",
       " '../data/gutenberg/1661-0.txt',\n",
       " '../data/gutenberg/98-0.txt',\n",
       " '../data/gutenberg/25344-0.txt']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import path\n",
    "book_files = []\n",
    "for book in open(f\"{home}/csc-369-student/data/gutenberg/order.txt\").read().split(\"\\n\"):\n",
    "    if path.isfile(f'{home}/csc-369-student/data/gutenberg/{book}-0.txt'):\n",
    "        book_files.append(f'../data/gutenberg/{book}-0.txt')\n",
    "book_files[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What is our top book?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿                  St. Benedict’s Rule for Monasteries\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online at\n",
      "http://www.gutenberg.org/license. If you are not located in the United\n"
     ]
    }
   ],
   "source": [
    "!head {book_files[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What is our second book?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿\n",
      "The Project Gutenberg EBook of Pride and Prejudice, by Jane Austen\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.org\n",
      "\n",
      "\n",
      "Title: Pride and Prejudice\n"
     ]
    }
   ],
   "source": [
    "!head {book_files[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercise 1:** Write a function that counts the number of times a word appears in a book. In other words, we want to know the frequencies of the words in each book. One way to store this is in a dictionary for each book. Do not worry about punctuation or capitalization. This is just an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "../data/gutenberg/50040-0.txt    {'﻿': 1, 'St.': 6, 'Benedict’s': 2, 'Rule': 22...\n",
       "../data/gutenberg/1342-0.txt     {'﻿': 1, 'The': 271, 'Project': 78, 'Gutenberg...\n",
       "../data/gutenberg/84-0.txt       {'﻿Project': 1, 'Gutenberg's': 1, 'Frankenstei...\n",
       "../data/gutenberg/6133-0.txt     {'﻿The': 1, 'Project': 78, 'Gutenberg': 21, 'E...\n",
       "../data/gutenberg/46-0.txt       {'﻿The': 1, 'Project': 78, 'Gutenberg': 21, 'E...\n",
       "                                                       ...                        \n",
       "../data/gutenberg/730-0.txt      {'﻿The': 1, 'Project': 79, 'Gutenberg': 22, 'E...\n",
       "../data/gutenberg/113-0.txt      {'﻿': 1, 'The': 219, 'Project': 79, 'Gutenberg...\n",
       "../data/gutenberg/1998-0.txt     {'﻿The': 1, 'Project': 78, 'Gutenberg': 20, 'E...\n",
       "../data/gutenberg/53854-0.txt    {'﻿The': 1, 'Project': 79, 'Gutenberg': 22, 'E...\n",
       "../data/gutenberg/209-0.txt      {'﻿': 1, 'The': 112, 'Project': 79, 'Gutenberg...\n",
       "Length: 74, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_word_freq = Chapter2_helper.count_words(book_files)\n",
    "import pandas as pd\n",
    "pd.Series(book_word_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**If you want to time it, there is a magic command for that.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%timeit -n 1\n",
    "book_word_freq = Chapter2_helper.count_words(book_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GNU Parallel\n",
    "One of my favorite command line finds of all time: <a href=\"https://www.gnu.org/software/parallel/\">https://www.gnu.org/software/parallel/</a>. This flexible program provides an easy to use way of running the same command in *parrallel*. The arguments may differ between commands. Here are some examples. This is a silly example, but it illustrates the point of *parallel*. Let's say you want to list the contents of three directors: dir1, dir2, and dir3. You can do this with:\n",
    "\n",
    "```bash\n",
    "$ ls dir1\n",
    "\n",
    "$ ls dir2\n",
    "\n",
    "$ ls dir3\n",
    "```\n",
    "\n",
    "Using parallel you can do:\n",
    "\n",
    "```bash\n",
    "parallel ls {} ::: dir1 dir2 dir3\n",
    "```\n",
    "\n",
    "This command can be brocken down into the list after ::: that is split and inserted into {}. This is how we execute the three listings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our small example on <100 books did not take very long. This wouldn't classify as something that needs distributed computing. But consider how likely it is that instead of counting words, we are doing something more computationally intensive. OR consider that we may be doing something simple like counting words, but instead of a few books, it is the internet itself...\n",
    "\n",
    "My point is that depending on the application you may want to take something you've written and run it in parallel. While there are language extensions for this, we are focusing on command line distributed computing execution as that is often a good fit for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!ls Chapter2_count_words_book.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Running parallel\n",
    "\n",
    "Let's break down the following command. \n",
    "* Identify the pipes. What are they doing?\n",
    "* What is the structure of the find command?\n",
    "* What happened to the ::: in the parallel command\n",
    "* What does the -v mean in the egrep command?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!find {home}/csc-369-student/data/gutenberg -name \"*.txt\" | egrep -v order.txt | parallel echo {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often I do this kind of pattern where echo is the last command. This helps me debug before I even get started. To me programming is about debugging more than anything. The better I am at debugging, the better programmer. \n",
    "\n",
    "Next we will use our script Chapter2_count_words_book.py and *parallel* to perform a distributed computation of counting words in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%timeit -n 1\n",
    "!find {home}/csc-369-student/data/gutenberg -name \"*.txt\" | egrep -v order.txt | parallel python Chapter2_count_words_book.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Results\n",
    "* We got a speedup even though we had to start Python multiple times (our results may vary on a shared environment). \n",
    "* There is always overhead when moving towards distributed computing. \n",
    "* We aren't going to do the actual comparison of top 25 to next 25. \n",
    "* Well... why not. We are almost there. This material is definitely not part of this class though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "book_word_freq = Chapter2_helper.count_words(book_files)\n",
    "\n",
    "top_books = book_files[:25]\n",
    "next_books = book_files[25:50]\n",
    "\n",
    "top_df = pd.DataFrame(columns=[\"book\",\"word\",\"freq\",\"group\"]).set_index([\"book\",\"word\"])\n",
    "next_df = pd.DataFrame(columns=[\"book\",\"word\",\"freq\",\"group\"]).set_index([\"book\",\"word\"])\n",
    "\n",
    "# Normalize the counts for each book\n",
    "for book in top_books:\n",
    "    data = pd.Series(book_word_freq[book])\n",
    "    data = (data/data.sum()).to_frame().reset_index()\n",
    "    data.columns=[\"word\",\"freq\"]\n",
    "    data[\"book\"] = book\n",
    "    data[\"group\"] = \"top\"\n",
    "    top_df = top_df.append(data.set_index([\"book\",\"word\"]))\n",
    "    \n",
    "for book in next_books:\n",
    "    data = pd.Series(book_word_freq[book])\n",
    "    data = (data/data.sum()).to_frame().reset_index()\n",
    "    data.columns=[\"word\",\"freq\"]\n",
    "    data[\"book\"] = book\n",
    "    data[\"group\"] = \"bottom\"\n",
    "    next_df = next_df.append(data.set_index([\"book\",\"word\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "next_df = next_df.reset_index()\n",
    "top_df = top_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_df = top_df.append(next_df)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pivot_df = plot_df.groupby(['word','group']).mean().reset_index().pivot_table(index='group',columns='word').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "top_k = 30\n",
    "top_words = [v[1] for v in (pivot_df[\"bottom\"] - pivot_df[\"top\"]).abs().sort_values(ascending=False)[:top_k].index]\n",
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "alt.Chart(plot_df.set_index('word').loc[top_words].reset_index()).mark_bar().encode(\n",
    "    x='group',\n",
    "    y='freq',\n",
    "    column='word',\n",
    "    color='group'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Anyways...** I feel like we've gotten that out of our system. In reality, we need to perform a lot more data cleaning and data organization before such an analysis will yield what we want.\n",
    "\n",
    "Now back to distributed computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wrapping up our warmup\n",
    "There is so much more to Parallel then we can discuss here. \n",
    "\n",
    "For example, you can use Parallel to execute commands on multiple nodes: <a href=\"https://www.gnu.org/software/parallel/parallel_tutorial.html#Remote-execution\">https://www.gnu.org/software/parallel/parallel_tutorial.html#Remote-execution</a>. \n",
    "\n",
    "Parallel is one of the most useful distributed computing tools at your disposal. If you have a command line program that would benefit from running in a distributed fashion. Do NOT rewrite it until you have considered running it this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Questions\n",
    "1. Describe an instance where you would reach for GNU parallel instead of more advanced and integrated solutions.\n",
    "\n",
    "\n",
    "2. When solving a distributed computing problem, what doesn't GNU parallel do for you? What did you have to implement in the lab?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Detour: Linux and Bash\n",
    "\n",
    "While there are many tutorials and introduction to Bash, I like this one: https://ubuntu.com/tutorials/command-line-for-beginners. You may do almost the entire tutorial directly in this notebook. There are several ways to run Bash within Jupyter. Here are some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to push!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_code_all_hidden": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,md,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
